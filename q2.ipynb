{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Decision tree"
      ],
      "metadata": {
        "id": "-AeBYldeesvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install and import library"
      ],
      "metadata": {
        "id": "5RikxJsQfbin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tfds-nightly tensorflow matplotlib"
      ],
      "metadata": {
        "id": "wwxjnDu_ghX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-datasets"
      ],
      "metadata": {
        "id": "jUl_Z46Mg7Zq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "ROecx2VIgFhP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a class for the decision tree node"
      ],
      "metadata": {
        "id": "3FAXdY2AhmkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  def __init__(self, depth):\n",
        "    # Initialize the node attributes\n",
        "    self.depth = depth # The depth of the node in the tree\n",
        "    self.split_feature = None # The feature to split on\n",
        "    self.split_value = None # The value to split on\n",
        "    self.left = None # The left child node\n",
        "    self.right = None # The right child node\n",
        "    self.label = None # The label of the node if it is a leaf\n",
        "\n",
        "  def _is_leaf(self):\n",
        "    # Check if the node is a leaf\n",
        "    return self.label is not None\n",
        "\n",
        "  def entropy(self, y):\n",
        "    # Calculate the entropy of a label array y\n",
        "    _, counts = np.unique(y, return_counts=True)\n",
        "    probs = counts / len(y)\n",
        "    return -np.sum(probs * np.log2(probs))\n",
        "\n",
        "  def information_gain(self, x, y):\n",
        "    # Calculate the information gain of a feature array x and a label array y\n",
        "    # Information gain is the reduction in entropy after splitting on x\n",
        "    entropy_before = self.entropy(y)\n",
        "    # Split the data into two subsets based on x\n",
        "    left_mask = x <= np.median(x)\n",
        "    right_mask = x > np.median(x)\n",
        "    y_left = y[left_mask]\n",
        "    y_right = y[right_mask]\n",
        "    # Calculate the entropy of each subset\n",
        "    entropy_left = self.entropy(y_left)\n",
        "    entropy_right = self.entropy(y_right)\n",
        "    # Calculate the weighted average of the entropy after splitting\n",
        "    entropy_after = (len(y_left) / len(y)) * entropy_left + (len(y_right) / len(y)) * entropy_right\n",
        "    # Return the information gain\n",
        "    return entropy_before - entropy_after\n",
        "\n",
        "  def information_gains(self, X, y):\n",
        "    # Calculate the information gain of each feature in X and a label array y\n",
        "    # Return a numpy array of information gains\n",
        "    gains = []\n",
        "    for i in range(X.shape[1]):\n",
        "      x = X[:, i]\n",
        "      gain = self.information_gain(x, y)\n",
        "      gains.append(gain)\n",
        "    return np.array(gains)\n",
        "\n",
        "  def fit(self, X_train, y_train):\n",
        "    # Fit the node to the training data\n",
        "    # If the node is pure (only one label) or the depth limit is reached, make it a leaf node and assign the majority label\n",
        "    if len(np.unique(y_train)) == 1 or self.depth == 0:\n",
        "      self.label = np.bincount(y_train).argmax()\n",
        "      return\n",
        "    # Otherwise, find the best feature to split on based on information gain\n",
        "    gains = self.information_gains(X_train, y_train)\n",
        "    self.split_feature = gains.argmax()\n",
        "    self.split_value = np.median(X_train[:, self.split_feature])\n",
        "    # Split the data into two subsets based on the best feature\n",
        "    left_mask = X_train[:, self.split_feature] <= self.split_value\n",
        "    right_mask = X_train[:, self.split_feature] > self.split_value\n",
        "    X_left = X_train[left_mask]\n",
        "    y_left = y_train[left_mask]\n",
        "    X_right = X_train[right_mask]\n",
        "    y_right = y_train[right_mask]\n",
        "    # Create two child nodes and recursively fit them to the subsets\n",
        "    self.left = Node(self.depth - 1)\n",
        "    self.left.fit(X_left, y_left)\n",
        "    self.right = Node(self.depth - 1)\n",
        "    self.right.fit(X_right, y_right)\n",
        "\n",
        "  def predict(self, X):\n",
        "    # Predict the label for a single input array X\n",
        "    # If the node is a leaf, return its label\n",
        "    if self._is_leaf():\n",
        "      return self.label\n",
        "    # Otherwise, traverse to the left or right child node based on the split feature and value\n",
        "    if X[self.split_feature] <= self.split_value:\n",
        "      return self.left.predict(X)\n",
        "    else:\n",
        "      return self.right.predict(X)"
      ],
      "metadata": {
        "id": "OXPeyqLehpch"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training & Testing"
      ],
      "metadata": {
        "id": "wfCnqAhCii_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset and scale it to [0, 1]\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Reshape the data from 28x28 matrix to 784 array\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "# Initialize the PCA and fit it on the training data\n",
        "pca = PCA(n_components=10)\n",
        "pca.fit(x_train)\n",
        "\n",
        "# Transform the training and test data using PCA\n",
        "x_train_pca = pca.transform(x_train)\n",
        "x_test_pca = pca.transform(x_test)\n",
        "\n",
        "# Convert the reduced datasets types to dataframe using pd\n",
        "x_train_pca = pd.DataFrame(x_train_pca)\n",
        "x_test_pca = pd.DataFrame(x_test_pca)\n",
        "\n",
        "# Initialize the decision tree node with depth 10\n",
        "dt = Node(depth=10)\n",
        "\n",
        "# Train the node on the training data\n",
        "dt.fit(x_train_pca.values, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = [dt.predict(x) for x in x_test_pca.values]\n",
        "\n",
        "# Report the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "nxQ7h1WPiCJ9",
        "outputId": "c064a3f4-c495-4238-db12-efa77ccf3d13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Accuracy: 0.8019\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}